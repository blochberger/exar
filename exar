#!/usr/bin/env python3

import os
import plistlib
import sys
import uuid

from argparse import ArgumentParser
from mimetypes import guess_extension
from urllib.parse import urlparse, unquote
from typing import Any, Dict, List, Optional


try:
	from termcolor import colored
except ModuleNotFoundError:
	def colored(msg, *args, **kwargs):
		return msg


def error(msg: str) -> None:
	print(colored(msg, 'red'), file=sys.stderr)


def fatal(msg: str, exit_code: int = 1) -> None:
	error(msg)
	exit(exit_code)


def warning(msg: str) -> None:
	print(colored(msg, 'yellow'), file=sys.stderr)


def info(msg: str) -> None:
	print(colored(msg, 'blue'))


def success(msg: str) -> None:
	print(colored(msg, 'green'))


def filename_from_url(urlstr: str, mimetype: Optional[str] = None) -> str:
	url = urlparse(urlstr)
	filename = unquote(url.path)
	if filename.startswith('/'):
		filename = filename[1:]
	if url.scheme == 'data':
		filename = str(uuid.uuid4())
		extension = guess_extension(mimetype)
		if extension is None:
			warning("Unknown MIME type: {}".format(mimetype))
		else:
			filename += extension
	return filename


def main() -> None:
	parser = ArgumentParser(
		description="Extracts resources from Safari web archives."
	)

	mode_group = parser.add_mutually_exclusive_group()
	mode_group.add_argument(
		'--list-mimetypes',
		help="List occuring MIME types of sub resources.",
		action='store_true',
		default=False,
	)
	mode_group.add_argument(
		'--list-urls',
		help="List URLs of sub resources.",
		action='store_true',
		default=False,
	)
	mode_group.add_argument(
		'--list-filenames',
		help="List file names of subresources.",
		action='store_true',
		default=False,
	)

	force_group = parser.add_mutually_exclusive_group()
	force_group.add_argument(
		'-f', '--force',
		help="Overwrites files, if they exist.",
		action='store_true',
		default=False,
	)
	force_group.add_argument(
		'-a', '--autoname',
		help="Automatically rename file, if they exist.",
		action='store_true',
		default=False,
	)

	parser.add_argument(
		'--autoext',
		help="Automatically append file extensions if missing.",
		action='store_true',
		default=False,
	)
	parser.add_argument(
		'-o', '--out',
		help="The path where the extracted files will be stored.",
		default=None,
	)
	parser.add_argument(
		'--remove',
		help="Remove the original web archive after successful extraction.",
		action='store_true',
		default=False,
	)
	parser.add_argument(
		'webarchives',
		help="Paths to the web archives.",
		nargs='*',
	)
	args = parser.parse_args()

	fns = args.webarchives
	list_mimetypes = args.list_mimetypes
	list_urls = args.list_urls
	list_filenames = args.list_filenames
	overwrite = args.force
	autoname = args.autoname
	autoext = args.autoext
	extract = not (list_mimetypes or list_urls or list_filenames)
	remove = args.remove

	for archive in fns:
		archive = os.path.expanduser(archive)

		# Determine name of output directory
		if not extract:
			extract_path = None
		elif args.out is None:
			extract_path = archive
			if archive.endswith('.webarchive'):
				extract_path = extract_path[:-len('.webarchive')]
			else:
				extract_path += '_out'
		else:
			extract_path = os.path.expanduser(args.out)

		if not os.path.exists(archive):
			fatal("The file does not exist: {}".format(fn))

		with open(archive, 'rb') as fp:
			plist: Dict[str, Any] = plistlib.load(fp)

		if 'WebSubresources' not in plist:
			warning("No subresources.")
			return

		subresources: List[Dict[str, Any]] = plist['WebSubresources']

		if len(subresources) == 0:
			warning("No subresources.")
			return

		mimetypes = set()
		urls = []
		filenames = []
		subresource_id = 1
		for subresource in subresources:
			expected_keys = {'WebResourceData', 'WebResourceMIMEType', 'WebResourceURL'}
			missing_keys = expected_keys.difference(set(subresource.keys()))
			if missing_keys:
				error("Missing keys: {}".format(missing_keys))
				continue

			data: bytes = subresource['WebResourceData']
			mimetype: str = subresource['WebResourceMIMEType']
			urlstr: str = subresource['WebResourceURL']

			# Determine filename
			fn = filename_from_url(urlstr, mimetype)

			if extract_path is not None:
				extract_fn = os.path.join(extract_path, fn)

				head, tail = os.path.splitext(extract_fn)
				if not tail and autoext:
					extract_fn = head + (guess_extension(mimetype) or '')

				while os.path.exists(extract_fn) and autoname:
					head, tail = os.path.splitext(extract_fn)
					extract_fn = '{}_{:03d}{}'.format(
						head,
						subresource_id,
						tail,
					)
					subresource_id += 1

				if os.path.exists(extract_fn) and not overwrite:
					warning("File '{}' exists, skipped.".format(extract_fn))
				else:
					os.makedirs(os.path.dirname(extract_fn), exist_ok=True)
					with open(extract_fn, 'wb') as fp:
						fp.write(data)
					success("Extracted '{}'".format(extract_fn))

			mimetypes.add(mimetype)
			urls.append(urlstr)
			filenames.append(fn)

		if extract and remove:
			os.remove(archive)
			info("Removed '{}'".format(archive))

		if list_mimetypes:
			print('\n'.join(sorted(list(mimetypes))))
		elif list_urls:
			print('\n'.join(urls))
		elif list_filenames:
			print('\n'.join(filenames))


if __name__ == '__main__':
	main()
